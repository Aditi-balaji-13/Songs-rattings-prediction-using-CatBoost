# -*- coding: utf-8 -*-
"""mm18b007_mm19b022.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Bm7dKJn2RzlgEu5EDIMF6-J58WyrOCDL
"""

import numpy as np
import pandas as pd
from catboost import CatBoostRegressor
from scipy import stats
from sklearn.model_selection import train_test_split

def resumetable(df):
    print(f"Dataset Shape: {df.shape}")
    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])
    summary = summary.reset_index()
    summary['Name'] = summary['index']
    summary = summary[['Name','dtypes']]
    summary['Missing'] = df.isnull().sum().values    
    summary['Uniques'] = df.nunique().values
    summary['First Value'] = df.loc[0].values
    summary['Second Value'] = df.loc[1].values
    return summary

df = pd.read_csv(r"/Users/aditib/Desktop/IITM academics/sem4 stuff'/PRML MKN Jan-21 Dataset/train.csv")
df1 = pd.read_csv(r"/Users/aditib/Desktop/IITM academics/sem4 stuff'/PRML MKN Jan-21 Dataset/test.csv")
df2 = pd.read_csv(r"/Users/aditib/Desktop/IITM academics/sem4 stuff'/PRML MKN Jan-21 Dataset/songs.csv")
df3 = pd.read_csv(r"/Users/aditib/Desktop/IITM academics/sem4 stuff'/PRML MKN Jan-21 Dataset/song_labels.csv")
df4 = pd.read_csv(r"/Users/aditib/Desktop/IITM academics/sem4 stuff'/PRML MKN Jan-21 Dataset/save_for_later.csv")

df4.insert(2,'wweight','yes')

g = df3.groupby('platform_id')
platid = np.array(df3.platform_id.unique())
w_avg = np.zeros(len(platid))
n_user = np.zeros(len(platid))
var = np.zeros(len(platid))
for grp in range(len(platid)):
    val = np.array(g.get_group(platid[grp])['label_id'])
    wt = np.array(g.get_group(platid[grp])['count'])
    w_avg[grp] = np.average(val, weights = wt)
    n_user[grp] = np.log(np.sum(wt))
    var[grp] = np.log(np.sum(((val - w_avg[grp])**2)@wt)/n_user[grp])
    
combine = {"platform_id" : platid, "avg_label_id" : w_avg, "count":n_user}
df3_1 = pd.DataFrame(combine)

g1 = df.groupby('song_id')
num = g1.std()['score']
num.rename('std_dev_score', inplace = True)

g2 = df.groupby(['song_id','score']).count()
g2['customer_id'] = np.log(g2['customer_id'])
p1 = g2.pivot_table(index = 'song_id', columns = 'score', values = 'customer_id', fill_value = 0)
p1.columns = ['r_1','r_2','r_3','r_4','r_5']

g3 = df2.groupby('released_year').count()
year_song_count = g3['song_id']
year_song_count.rename('yearly_song_count', inplace = True)

g4 = df.groupby('customer_id').mean()
customer_mean_rate = g4['score']
customer_mean_rate.rename('customer_mean_rate', inplace = True)

df_FE = pd.merge(df,df2,how = 'left', on = 'song_id')
df_FE = pd.merge(df_FE,df3_1, how = 'left', on = 'platform_id')
g5 = df_FE.groupby(['customer_id','score']).mean()

g5['avg_label_id'] = (g5['avg_label_id'])**3
p2 = g5.pivot_table(index = 'customer_id', columns = 'score', values = 'avg_label_id', fill_value = 0)
p2.columns = ['lab_1', 'lab_2', 'lab_3', 'lab_4', 'lab_5']

p3 = g5.pivot_table(index = 'customer_id', columns = 'score', values = 'released_year', fill_value = '')
p3.columns = ['ry_1', 'ry_2', 'ry_3', 'ry_4', 'ry_5']

data = pd.merge(df,df2,how = 'left', on = 'song_id')
data = pd.merge(data, year_song_count, on = 'released_year', how = 'left')
data = pd.merge(data,df3_1, how = 'left', on = 'platform_id')
data = pd.merge(data, df4, how = 'left', on = ['customer_id','song_id'])
data = pd.merge(data,p1, on = 'song_id', how = 'left')
data = pd.merge(data,num, on = 'song_id', how = 'left')
data = pd.merge(data, customer_mean_rate, on = 'customer_id', how = 'left')
data = pd.merge(data, p2, on = 'customer_id', how = 'left')
data = pd.merge(data, p3, on = 'customer_id', how = 'left')


data = data.drop(columns = ['language'])

data['number_of_comments'] = np.log(data['number_of_comments'])
data['song_id'] = np.log(data['song_id'])

data['released_year'] = data['released_year'].fillna('')
data['number_of_comments'] = data['number_of_comments'].fillna(0)
data['avg_label_id'] = data['avg_label_id'].fillna('')
#data['var_label_id'] = data['var_label_id'].fillna('')
data['platform_id'] = data['platform_id'].replace(np.nan, '')
data['wweight'] = data['wweight'].fillna('no')
data['count'] = data['count'].fillna(0)
data['std_dev_score'] = data['std_dev_score'].fillna('')
data['yearly_song_count'] = data['yearly_song_count'].fillna('')

resumetable(data)

data1 = pd.merge(df1,df2,how = 'left', on = 'song_id')
data1 = pd.merge(data1, year_song_count, on = 'released_year', how = 'left')
data1 = pd.merge(data1,df3_1, how = 'left', on = 'platform_id')
data1 = pd.merge(data1, df4, how = 'left', on = ['customer_id','song_id'])
data1 = pd.merge(data1,p1, on = 'song_id', how = 'left')
data1 = pd.merge(data1,num, on = 'song_id', how = 'left')
data1 = pd.merge(data1, customer_mean_rate, on = 'customer_id', how = 'left')
data1 = pd.merge(data1, p2, on = 'customer_id', how = 'left')
data1 = pd.merge(data1, p3, on = 'customer_id', how = 'left')


data1 = data1.drop(columns = ['language'])

data1['number_of_comments'] = np.log(data1['number_of_comments'])
data1['song_id'] = np.log(data1['song_id'])

data1['released_year'] = data1['released_year'].fillna('')
data1['number_of_comments'] = data1['number_of_comments'].fillna(0)
data1['avg_label_id'] = data1['avg_label_id'].fillna('')
#data1['var_label_id'] = data1['var_label_id'].fillna('')
data1['platform_id'] = data1['platform_id'].replace(np.nan, '')
data1['wweight'] = data1['wweight'].fillna('no')
data1['count'] = data1['count'].fillna(0)
data1['std_dev_score'] = data1['std_dev_score'].fillna('')
data1['yearly_song_count'] = data1['yearly_song_count'].fillna('')
resumetable(data1)

target_col = "score"
x = data.loc[:, data.columns != target_col]
y = data.loc[:, target_col]
X_test = data1.loc[:,data1.columns]

X_train, X_cross, y_train , y_cross = train_test_split(x, y, test_size=0.2, random_state=42)

features = list(X_train.columns)

categorical_features_indices = ["customer_id","platform_id","wweight"]

model_cb = CatBoostRegressor(loss_function='RMSE',cat_features= categorical_features_indices, depth = 10, learning_rate = 0.1)

model_cb.fit(X_train, y_train, cat_features= categorical_features_indices,
             eval_set=(X_cross, y_cross))

y_pred = model_cb.predict(X_test)

data2 = pd.read_csv(r"/Users/aditib/Desktop/IITM academics/sem4 stuff'/PRML MKN Jan-21 Dataset/dummy_submission.csv")
data2['score'] = y_pred
data2.to_csv(r"/Users/aditib/Desktop/IITM academics/sem4 stuff'/PRML MKN Jan-21 Dataset/dummy_submission.csv", index = False)